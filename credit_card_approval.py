# -*- coding: utf-8 -*-
"""Credit Card Approval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SI5YtNZ36V305FFxt87wvfb0V0T-JBNL

# Data Loading
"""

# connect colab to google drive
from google.colab import drive
drive.mount('/content/drive')

#importing libraries
import json
import pandas as pd
import urllib.request
import yaml
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

#Loading the paths
url1 = '/content/drive/MyDrive/Product Demand Forecasting/application_record.json'
url2 = '/content/drive/MyDrive/Product Demand Forecasting/credit_record.json'

#loading the json files
with open(url1, 'r') as f:
  data1 = json.load(f)

with open(url2, 'r') as a:
  data2 = json.load(a)

#checking the data
data1

#using the results in the dataset
d1_results = data1['results']
d2_results = data2['results']

df1 = pd.DataFrame.from_dict(d1_results)
df2 = pd.DataFrame.from_dict(d2_results)

df1

df2.head()

df = pd.merge(df1, df2, on="ID")

df.to_csv('out.csv')

df

df.isnull().sum()

df.duplicated().sum()

#checking the dtypes of the dataframe
df.dtypes

#converting the ID to string
df['ID'] = df['ID'].astype(str)
df.dtypes

#checking the count
df['FLAG_OWN_CAR'].value_counts()

df['NAME_INCOME_TYPE'].value_counts()

df['NAME_EDUCATION_TYPE'].value_counts()

df['STATUS'].value_counts()

df['OCCUPATION_TYPE'].value_counts()

#We can see that there are null values below

#renaming the null values to other

df.OCCUPATION_TYPE.replace("", 'Other', inplace = True)

#now we check again
df['OCCUPATION_TYPE'].value_counts()

#replace values
# x c 0 = 1
#rest 0
vals_to_replace = {'X': '1',
                   'C': '1',
                   0: '1',
                   1: '0',
                   2: '0',
                   3: '0',
                   4: '0',
                   5: '0'}
df['STATUS'] = df['STATUS'].map(vals_to_replace).fillna(df['STATUS'])

df

df['STATUS'].value_counts()

#PIVOT TABLE
df_pivot = df.pivot_table(index= ['NAME_INCOME_TYPE', 'OCCUPATION_TYPE'])
df_pivot

df.describe()

type(df['STATUS'])

"""
# Is there a relationship between Education Type and STATUS?"""

df_denied = df[df['STATUS'] == '0']
df_approved = df[df['STATUS'] == '1']
df_den_edu = df_denied['NAME_EDUCATION_TYPE'].value_counts()
df_den_edu.plot.bar(rot=0)

df_app_edu = df_approved['NAME_EDUCATION_TYPE'].value_counts()
df_app_edu.plot.bar(rot=0)

#We can see that the education degree doesn't really impact the approval and denial of credit card as the the graphs show.

df_approved.head()

"""# What occupation has the highest percentage of approval? What occupation has the lowest percentage of approval?"""

df_approved['OCCUPATION_TYPE'].value_counts()
df['OCCUPATION_TYPE'].value_counts()
df_perc_approved = (df_approved['OCCUPATION_TYPE'].value_counts()/df['OCCUPATION_TYPE'].value_counts())*100
df_perc_approved

#As we can see, low-skill laborers have the highest percentage of approval percentage of 94.29%
#Whereas, Medicine staff has the lowest percentage of approval percentage of 42.65%

df_denied['OCCUPATION_TYPE'].value_counts()
df['OCCUPATION_TYPE'].value_counts()
df_perc_denied = (df_denied['OCCUPATION_TYPE'].value_counts()/df['OCCUPATION_TYPE'].value_counts())*100
df_perc_denied
#As we can see the medicine staff the highest percentage of rejection which is 57.35
#And low-skill laborers have the least percentage of rejection with only 5.71%

"""# What is the average count of family members for the credit card approval and denial?

"""

df_denied['CNT_FAM_MEMBERS'].mean()

df_approved['CNT_FAM_MEMBERS'].mean()

#We can see that the average for the approved indivuals is more than that for the people who have been denied

"""# Data Exploration and Visualization

viz.1: People who have and dont have car distributed on the basis of their occupation
"""

sns.set(rc={'figure.figsize':(30,3)}, palette=['#432371',"#FAAE7B"])
sns.countplot(x='OCCUPATION_TYPE',hue='FLAG_OWN_CAR',data=df)
plt.xlabel('occupation type')

plt.ylabel('own car')
plt.title('car by occupation type')

"""viz.2: Overall distribution of gender, car and realty ownership"""

fig, axes = plt.subplots(1,3)

pie1= df['CODE_GENDER'].value_counts().plot.pie(explode=[0.1,0.1],
                                                autopct='%1.1f%%',
                                                shadow=True,
                                                colors=["#76B5B3","#EC9B9A"],
                                                textprops = {'fontsize':12}, ax=axes[0])
pie1.set_title("Customer Distribution by Gender")

pie2 = df['FLAG_OWN_CAR'].value_counts().plot.pie(explode=[0.1,0.1],
                                                 autopct='%1.1f%%',
                                                 shadow=True,
                                                 colors=["#80DE99","#00CECB"],
                                                 textprops = {'fontsize':12}, ax=axes[1])
pie2.set_title("Car Ownership")

pie3 = df['FLAG_OWN_REALTY'].value_counts().plot.pie(explode=[0.1,0.1],
                                                     autopct='%1.1f%%',
                                                     shadow=True,
                                                     colors=["#76B5B3","#00CECB"],
                                                     textprops = {'fontsize':12}, ax=axes[2])
pie3.set_title("Realty Ownership")

fig.set_size_inches(14,5)

plt.tight_layout()

plt.show()

"""# Decision Tree Prediction"""

# Import required libraries
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd
from sklearn.preprocessing import LabelEncoder


# Drop irrelevant columns
data =df.drop(['ID', 'OCCUPATION_TYPE', 'FLAG_MOBIL','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS'], axis=1)

# Split the dataset into training and testing data
X = data.drop('STATUS', axis=1) # Feature variables
y = data['STATUS'] # Target variable
X = pd.get_dummies(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# Define the decision tree model
dec_tree = DecisionTreeClassifier(max_depth=5, random_state=42)

# Fit the model on the training data
dec_tree.fit(X_train, y_train)

# Predict the target variable on the test data
y_pred = dec_tree.predict(X_test)

# Evaluate the model using the accuracy metric
accuracy = accuracy_score(y_test, y_pred)

# Print the evaluation metric
print('Accuracy:', accuracy)